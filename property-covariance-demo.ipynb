{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring covariance between properties across scales\n",
    "**Authors**: Benjamin Jasperson, Harley T. Johnson\n",
    "\n",
    "**GitHub URL**: https://github.com/bjasperson/property-covariance-demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Information\n",
    "\n",
    "This workbook explores the use of interatomic potential (IP)-generated data to uncover correlations between fundamental microscopic properties, which we call canonical properties, and large-scale quantities of interest (QoI).\n",
    "It closely follows the work outlined in [this manuscript](https://doi.org/10.1016/j.actamat.2025.120722).\n",
    "\n",
    "As a proof-of-principle, we'll use grain boundary (GB) energy as our QoI. \n",
    "Specifically, we'll look at how canonical properties relate to the scaling factor in the universal lattice matching (LM) model of Runnels et al. (2016).\n",
    "You don't need to worry about how this coefficient is defined; see the paper for details. Just think of it as a scalar measure of grain boundary energy.\n",
    "\n",
    "By the end of this workbook, you will have:\n",
    "1. Explored a dataset of IP-generated property results, uncovering correlations that can be used in a multiscale regression model.\n",
    "2. Developed a regression model using canonical properties identified through k-fold cross-validation.\n",
    "3. Used the regression model with first-principles indicator properties to make a prediction for the GB scaling coefficient from first-principles canonical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score, LeaveOneOut, GridSearchCV\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model, svm\n",
    "\n",
    "from itertools import combinations\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data\n",
    "To begin, we need to import our project data. The data we will use is originally from [this manuscript](https://arxiv.org/abs/2411.16770), [published here](https://doi.org/10.1016/j.actamat.2025.120722). You can find the original paper repo [here](https://github.com/Johnson-Research-Group/gb_covariance).\n",
    "\n",
    "The data includes IP-generated canonical properties, along with an LM model scaling factor calculated from individual symmetric-tilt GB energy simulations.\n",
    "\n",
    "**Task**: Using pandas, download the CSV file with this [link](https://github.com/bjasperson/property-covariance-demo/blob/main/data/gb_data.csv?raw=true), save the dataframe as `df_data`, and look at the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_link = \"https://github.com/bjasperson/property-covariance-demo/blob/main/data/gb_data.csv?raw=true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data review\n",
    "It is important to get a feel for the data that you are working with. To make plotting a little nicer, we have a csv file with key/value pairs to convert the variable names into human readable format.  \n",
    "\n",
    "**Task**: import the label csv file, located at `./data/label_dict.csv`, and convert it to a dictionary called `label_dict` using pandas, for use with plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_label_dict(label_dict_path = \"https://github.com/bjasperson/property-covariance-demo/blob/main/data/label_dict.csv?raw=true\"):\n",
    "    \"\"\"import the ./data/label_dict.csv file, convert it to a dictionary\n",
    "\n",
    "    Args:\n",
    "        label_dict_path (str, optional): path to csv file with key/value pairs.\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary with df column names as keys, and human-readable label as value\n",
    "    \"\"\"\n",
    "    \n",
    "    return label_dict\n",
    "\n",
    "label_dict = import_label_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write a function that calculates the [correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) between two variables. \n",
    "\n",
    "**Task**: given our dataframe, create a function that uses [Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html) to calculate the correlation coefficient between each set of variables. First, make a copy of the dataframe and replace the column names with the human readable version from the label dictionary using list comprehension. Next, apply the `corr` method to the copied dataframe to create `df_corr`. Finally, sort both the columns *and* rows of `df_corr` based on how correlated the variable is to the scaling factor, `$E_0$`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_df(df, label_dict):\n",
    "    \"\"\"create df with correlation values\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): property data (columns) for a given IP (row) \n",
    "        label_dict (dict): the label dict from above, to convert label keys to human readable format\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: correlation coefficient between canonical properties and coeff ($E_0$). Sort both the columns and rows by how correlated they are with the coeff $E_0$.\n",
    "    \"\"\"\n",
    "\n",
    "    return df_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to look at how the different fundamental properties relate with each other and our Quantity of Interest (GB energy coefficient). To aid in this, we will look at two plots.\n",
    "\n",
    "First, let's plot a heat map of the correlation coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_plot(df, \n",
    "              label_list, \n",
    "              label_dict, \n",
    "              annot = False, \n",
    "              figsize = (10,10),\n",
    "              annotation_fontsize = 6,\n",
    "              tick_fontsize = 6,\n",
    "              ):\n",
    "    \n",
    "    df_corr = correlation_df(df[label_list], label_dict)\n",
    "    fig,ax = plt.subplots(figsize = (figsize[0],figsize[1]))\n",
    "    colors = sns.color_palette(\"vlag\", as_cmap=True)\n",
    "    sns.heatmap(df_corr, vmin = -1, vmax = 1, cmap=colors,\n",
    "                annot=annot,\n",
    "                xticklabels=True,\n",
    "                yticklabels=True,\n",
    "                fmt = '.1f',\n",
    "                annot_kws = {\"fontsize\":annotation_fontsize},\n",
    "                cbar_kws = {\"location\":\"top\"}\n",
    "                )\n",
    "    ax.tick_params(labelsize=tick_fontsize)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=tick_fontsize)\n",
    "\n",
    "label_list = df_data.columns.to_list()\n",
    "label_list.remove(\"crystal_type\")\n",
    "label_list.remove(\"species\")\n",
    "label_list.remove(\"model\")\n",
    "corr_plot(df_data, label_list, label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how properties that are highly correlated with each other appear as square blocks in the plot. This makes it easy to identify groups of properties that can easily be substituted for each other other in the model. \n",
    "\n",
    "Next, let's look at pairplots of the most correlated features. \n",
    "\n",
    "**Task**: create a function to plot a set of properties from the property dataframe. Use Seaborn pairplot, and set the marker color (`hue`) based on `species`. Explore different combinations of pairplots for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot_fun(df, \n",
    "                 params_list,  \n",
    "                 label_dict, \n",
    "                 height=1.5,\n",
    "                 ):\n",
    "    \"\"\"create pairplot for select indicator properties\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): dataframe of data that was previously imported\n",
    "        params_list (list): list of parameter strings to use\n",
    "        label_dict (dict): the label dict from above, to convert label keys to human readable format\n",
    "        height (float): pairplot height. Defaults to 2.0.\n",
    "        xlims (list): list of limits to use for plotting\n",
    "    \"\"\"\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "plot_param_list = [\"coeff\", \"lattice_constant_fcc\", \"lattice_constant_bcc\", 'intr_stack_fault_energy_fcc', 'unstable_stack_energy_fcc']\n",
    "pairplot_fun(df_data, plot_param_list, label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions to ponder:\n",
    "1. Did you find factors that you think are worth including?\n",
    "2. Do you see any outliers that we need to remove? How will you decide what is an outlier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying indicator properties\n",
    "\n",
    "Now that we have our data, we want to figure out which canonical properties will be best for our model. To do that, we'll use a [linear regression model](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares) with [k-fold cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html#k-fold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop regression model\n",
    "\n",
    "**Task**: Write a function that returns a linear regression pipeline. Your pipeline should include the following steps:\n",
    "- StandardScaler: for scaling the input values; helpful for SVR, used in LR for consistency. \n",
    "- KNNImputer: for filling in the missing property values in our data. Set `n_neighbors=2` and `keep_empty_features=True`\n",
    "- LinearRegression: the linear regression model (`linear_model.LinearRegression()`).\n",
    "\n",
    "Combine these in a `Pipeline` to facilitate easy use ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regr_pipeline():\n",
    "    \"\"\"creates a linear regression pipeline for modeling purposes\n",
    "\n",
    "    Returns:\n",
    "        sklearn.pipeline.Pipeline: linear regression pipeline\n",
    "    \"\"\"\n",
    "\n",
    "    return pipe\n",
    "\n",
    "pipe = linear_regr_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to make a list of the properties we are interested in considering as indicator properties for our model. A starting point is provided below.\n",
    "\n",
    "**If time**: explore different properties, and see if any new additions result in improved models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of parameters to explore\n",
    "params_list = ['lattice_constant_fcc',\n",
    "                'bulk_modulus_fcc', 'c11_fcc', 'c12_fcc', 'c44_fcc',\n",
    "                'extr_stack_fault_energy_fcc', 'intr_stack_fault_energy_fcc', 'unstable_stack_energy_fcc'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameter list, we want to make a list of possible combinations up to a certain number of factors. \n",
    "\n",
    "**Task**: write a function that uses the `combinations` function from `itertools` to make a list of lists, with possible combinations of factors up to `n_factor_max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subsets_list(factor_list, n_factor_max):\n",
    "    \"\"\"create all possible combinations of factors from a list, up to n_factor_max\n",
    "\n",
    "    Args:\n",
    "        factor_list (list): a list of individual factors (str) to consider\n",
    "        n_factor_max (int): maximum number of factors to consider in one model\n",
    "\n",
    "    Returns:\n",
    "        list: a list of lists, with each sub-list containing the factors (str) to include (e.g., ['c11_fcc', 'c12_fcc'])\n",
    "    \"\"\"\n",
    "\n",
    "    return subsets\n",
    "\n",
    "subsets = create_subsets_list(params_list, n_factor_max = 2)\n",
    "print(subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our list of possible factor combinations to consider. If we fit our model to the entire dataset, we aren't getting a realistic picture of the test error. So, we will use the `cross_val_score` package from scikit-learn to perform cross validation. Read more about it [here](https://scikit-learn.org/stable/modules/cross_validation.html).\n",
    "\n",
    "**Task**: write a function that iterates over each subset of the possible factor combinations. For each subset, use the `cross_val_score` package to perform cross-validation and return a score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_select_cv(df, pipe, subsets, label=\"coeff\", cv=None, scoring='r2'):\n",
    "    \"\"\"evaluates combinations of factors\n",
    "    \n",
    "    return a dataframe that includes one row per factor combination. list of parameters w/ cv score\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): dataframe of data that was previously imported\n",
    "        pipe (sklearn.pipeline.Pipeline): sklearn pipeline\n",
    "        subsets (list): a list of lists, with each sub-list containing the factors (str) to include (e.g., ['c11_fcc', 'c12_fcc'])\n",
    "        label (str, optional): the QoI label to use. Defaults to \"coeff\".\n",
    "        cv (int, optional): int, cross-validation generator or an iterable, Determines the cross-validation splitting strategy. Defaults to None.\n",
    "        scoring (str, optional): A str (see model evaluation documentation) or a scorer callable object / function with signature scorer(estimator, X, y) which should return only a single value. Defaults to 'r2'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: a dataframe of CV results\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run k-fold CV and get the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = TransformedTargetRegressor(regressor=pipe,\n",
    "#                                   transformer=StandardScaler())\n",
    "filename = \"kfold_models_lr\"\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state = 12345)\n",
    "df_results = factor_select_cv(df_data,\n",
    "                              pipe, \n",
    "                              subsets, \n",
    "                              cv=cv, \n",
    "                              scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If time**: repeat the steps above using different modeling approaches, e.g., support vector regression. Compare performance of the models, and try to understand why some perform better than others.\n",
    "\n",
    "Sort the values based on \"cv_score\", with `ascending=False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the top performing model and make a regression model to use. Make predictions and compare predicted versus actual. \n",
    "\n",
    "**Task**: fit a pipe against our IP data, using the best two-factor model. Make a prediction using the pipe, and add it to our `df_data` dataframe as \"coeff_pred\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at our results.\n",
    "\n",
    "**Task**: write a function that takes in the dataframe, plots the actual coefficient on the horizontal axis, and plots the predicted coefficient on the vertical axis. Use seaborn scatterplot with \"species\" as the hue. Set the aspect ratio to \"equal\" for each axis, and plot a line along the diagonal to represent a perfect prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_vs_actual_plot(df, \n",
    "                        figsize = (5,5),\n",
    "                        ):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    return\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions from first-principles indicator properties\n",
    "\n",
    "Now, we will import the DFT data that we will use with our model to make inferred predictions based on the indicator properties. First, get the data.\n",
    "\n",
    "**Task**: Using pandas, download the CSV file with this [link](https://github.com/bjasperson/property-covariance-demo/blob/main/data/gb_dft.csv?raw=true), save the dataframe as `df_dft`, and look at the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_link = \"https://github.com/bjasperson/property-covariance-demo/blob/main/data/gb_dft.csv?raw=true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two sets of properties now to consider: one for the IP data, and one for the DFT data. We want to decide which model to use for the DFT data. Let's filter our k-fold CV results to only include the DFT canonical properties.\n",
    "\n",
    "**Task:** Write a function that filters your model performance list from above based on the DFT properties available. Take in the cv results dataframe and a list of DFT properties (from the df_dft columns). If the properties for a given row are all available with DFT results, include it ([hint](https://www.geeksforgeeks.org/python-check-if-the-list-contains-elements-of-another-list/)). Return a dataframe of new, filtered results. Take a look at the top 5 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_model_results(df, dft_list):\n",
    "    \"\"\"takes in a df of k-fold CV results, and filters based on a list of properties\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): the k-fold CV df from above\n",
    "        dft_list (list): list of properties available from df_dft\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: filtered results from k-fold CV df\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Make a list that identifies the factors from the top performing model. Using your previously created function `add_pred`, make a prediction from DFT indicator properties and add the results to `df_dft` under the name \"dft_pred_coeff\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model of the 5 available DFT properties\n",
    "dft_model_properties = ['c44_fcc',  \n",
    "                        'unstable_stack_energy_fcc'\n",
    "                       ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the plotting function provided below to show a boxplot of coefficient results, along with the predicted versus actual DFT coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxplot(df_ip, \n",
    "                df_dft, \n",
    "                plot_errorbar = True,\n",
    "                order_list = [\"Ag\",\"Al\",\"Au\",\"Cu\",\"Ni\",\"Pd\",\"Pt\"]):\n",
    "    \"\"\"plot boxplot of dft GB results\n",
    "    \"\"\"\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(4,3))\n",
    "    sns.boxplot(data = df_ip, \n",
    "                x=\"species\", \n",
    "                y=\"coeff\", \n",
    "                order=order_list, \n",
    "                color = \"0.8\", \n",
    "                linewidth=1.0,\n",
    "                fliersize=5.0,\n",
    "                whis=0,\n",
    "                flierprops={\"marker\":\".\"},\n",
    "                zorder=1)\n",
    "    ax.set_ylabel(\"GB scaling coefficient\")\n",
    "\n",
    "    # add dft Xs\n",
    "    ax.scatter(df_dft['species'],\n",
    "               df_dft['dft_pred_coeff'], \n",
    "               marker='x', \n",
    "               s=100., \n",
    "               alpha=1.0, \n",
    "               color=\"r\",\n",
    "               label='\\n'.join(wrap(r\"$E_0$ regression prediction using DFT indicator properties\",20)),\n",
    "               zorder=3)\n",
    "\n",
    "    df_dft_gb_plot = df_dft[['species','dft_exact_coeff']].drop_duplicates()\n",
    "    df_dft_gb_plot = df_dft_gb_plot[df_dft_gb_plot['species'].isin(order_list)]\n",
    "    ax.scatter(df_dft_gb_plot['species'],\n",
    "               df_dft_gb_plot['dft_exact_coeff'], \n",
    "               marker='<', \n",
    "               s=50., \n",
    "               alpha=0.9, \n",
    "               color=\"r\",\n",
    "               label='\\n'.join(wrap(r\"$E_0$ fit directly to DFT GB results\",20)),\n",
    "               zorder=2)\n",
    "\n",
    "    # add errorbars if desired\n",
    "    if plot_errorbar == True:\n",
    "        ax.errorbar(df_dft['species'],\n",
    "                    df_dft['regr_coeff'], \n",
    "                    yerr = (df_dft['regr_coeff_lower'],\n",
    "                            df_dft['regr_coeff_upper']), \n",
    "                            fmt='.', \n",
    "                            markersize=0.0001, \n",
    "                            alpha=0.5, \n",
    "                            color=\"r\",\n",
    "                            #label='\\n'.join(wrap(\"Predicted strength using DFT indicator properties\",20)),\n",
    "                            elinewidth=2.0,\n",
    "                            capsize = 4)\n",
    "\n",
    "    fig.legend(bbox_to_anchor = (0.05,0.9,0.85,.15),#(0.,1.02,1.,.102),\n",
    "                    loc='lower left',\n",
    "                    mode=\"expand\",\n",
    "                    ncol = 2,\n",
    "                    fontsize= 8)\n",
    "\n",
    "    return \n",
    "\n",
    "get_boxplot(df_data, df_dft, plot_errorbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We see that our model predictions match the DFT results pretty well. \n",
    "\n",
    "Additional areas to explore, as time permits:\n",
    "- Right now, we are using all IP data to fit our model against, then make a prediction. To better estimate the predictive power of our model, we should reserve some data as test data. It makes sense to use cross-validation and report the average error, given our small dataset. Add in cross-validation to make it a more realistic prediction.\n",
    "- Using different combinations of factors, try to find a better model!\n",
    "- Explore different model types other than linear regression: SVR, ensemble of regressors, ...\n",
    "    - see [here](https://scikit-learn.org/stable/machine_learning_map.html) for ideas\n",
    "- Repeat the process, this time with the strength data\n",
    "    - [URL link to data](https://github.com/bjasperson/property-covariance-demo/blob/main/data/strength_data.csv?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
